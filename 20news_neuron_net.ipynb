{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-pOIGO18l66e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tXmlHhOymKXi"
   },
   "outputs": [],
   "source": [
    "categories = [\"comp.graphics\",\"sci.space\",\"rec.sport.baseball\"]\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train' ,categories=categories,remove=('headers','footers','quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories,remove=('headers','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1524730730312,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "a1l23v_PmKtM",
    "outputId": "8290eb5a-5f68-441d-ccd0-ec39408c5d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total texts in train:', 1774)\n",
      "('total texts in test:', 1180)\n"
     ]
    }
   ],
   "source": [
    "print('total texts in train:',len(newsgroups_train.data))\n",
    "print('total texts in test:',len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1524730731166,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "waZDEKRjmKwS",
    "outputId": "cc07076e-b65a-4865-a71d-d8e297dd0409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', u\"\\nBy '8 grey level images' you mean 8 items of 1bit images?\\nIt does work(!), but it doesn't work if you have more than 1bit\\nin your screen and if the screen intensity is non-linear.\\n\\nWith 2 bit per pixel; there could be 1*c_1 + 4*c_2 timing,\\nthis gives 16 levels, but they are linear if screen intensity is\\nlinear.\\nWith 1*c_1 + 2*c_2 it works, but we have to find the best\\ncompinations -- there's 10 levels, but 16 choises; best 10 must be\\nchosen. Different compinations for the same level, varies a bit, but\\nthe levels keeps their order.\\n\\nReaders should verify what I wrote... :-)\")\n",
      "('category:', 0)\n"
     ]
    }
   ],
   "source": [
    "print('text',newsgroups_train.data[0])\n",
    "print('category:',newsgroups_train.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "irkaTo7QmKzk"
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in newsgroups_train.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "for text in newsgroups_test.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1524730735562,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "BlCzXLtsmK2c",
    "outputId": "d1adde54-b847-426e-aee9-e33b8b7ffcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total words:', 85451)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words:\",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1524730736372,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "dgbzVGnzmK5M",
    "outputId": "c9c3015f-43c5-4776-e158-4084d1565a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Index of the word 'one':\", 1854)\n"
     ]
    }
   ],
   "source": [
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "        \n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)\n",
    "\n",
    "print(\"Index of the word 'one':\",word2index['one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4C7S-swXmK74"
   },
   "outputs": [],
   "source": [
    "def get_batch(data,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = data.data[i*batch_size:i*batch_size+batch_size]\n",
    "    categories = data.target[i*batch_size:i*batch_size+batch_size]\n",
    "    for text in texts:\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "            \n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        y = np.zeros((20),dtype=float)\n",
    "        for k in range(20):\n",
    "            if category == k:\n",
    "                y[k]=1.\n",
    "        results.append(y)\n",
    "     \n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1524730738016,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "fzRsOiLHmLAS",
    "outputId": "e865a670-023b-4dbf-9995-0a7f26ef226b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Each batch has 128 texts and each matrix has elements (words):', (128, 85451))\n"
     ]
    }
   ],
   "source": [
    "print(\"Each batch has 128 texts and each matrix has elements (words):\",get_batch(newsgroups_train,1,128)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1524730738838,
     "user": {
      "displayName": "tài bùi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113446466741417873365"
     },
     "user_tz": -420
    },
    "id": "m4HojYcOoFpW",
    "outputId": "d7e71b5d-f681-41d8-bcbc-053e306a81d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Each batch has 128 texts and each matrix has 3 categories:', (128, 20))\n"
     ]
    }
   ],
   "source": [
    "print(\"Each batch has 128 texts and each matrix has 3 categories:\",get_batch(newsgroups_test,1,128)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t9I84XRaoPQE"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "training_epochs = 5\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden = 100      # layer number of features\n",
    "n_input = total_words # Words in vocab\n",
    "n_classes = 20      \n",
    "\n",
    "tf_input = tf.placeholder(tf.float32,[None, n_input],name=\"input\")\n",
    "tf_output = tf.placeholder(tf.float32,[None, n_classes],name=\"output\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TYd7vw1dpLus"
   },
   "outputs": [],
   "source": [
    "def neuron_network(tf_input,weights,biases):\n",
    "    # hidden layer\n",
    "    layer_mul = tf.matmul(tf_input,weights['h1'])\n",
    "    layer_add = tf.add(layer_mul,biases['b1'])\n",
    "    layer = tf.nn.relu(layer_add)\n",
    "    \n",
    "    # output layer \n",
    "    out_layer_mul=tf.matmul(layer,weights['out'])\n",
    "    out_layer = tf.add(out_layer_mul,biases['out'])\n",
    "    \n",
    "    return out_layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hKBitfyzpxMu"
   },
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1': tf.Variable(tf.random_normal([n_input,n_hidden])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden,n_classes]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "logits=neuron_network(tf_input,weights,biases)\n",
    "\n",
    "# loss and optimizer\n",
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_output))\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "_dumcjVsqPDc",
    "outputId": "b9b8a5e4-bff0-4629-e8d6-0186613004cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'loss=', '83.265316743')\n",
      "('Epoch:', '0002', 'loss=', '4.690325517')\n",
      "('Epoch:', '0003', 'loss=', '6.089372072')\n",
      "('Epoch:', '0004', 'loss=', '4.622743740')\n",
      "('Epoch:', '0005', 'loss=', '1.333185417')\n",
      "Optimization Finished!\n",
      "('Accuracy:', 0.79067796)\n"
     ]
    }
   ],
   "source": [
    "init= tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "   # writer = tf.summary.FileWriter(' ./graphs' , sess.graph)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg = 0.\n",
    "        \n",
    "        total_batch = int(len(newsgroups_train.data)/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(newsgroups_train,i,batch_size)\n",
    "            \n",
    "            # Run optimization op  and cost op \n",
    "            loss,acc = sess.run([loss_op,optimizer], feed_dict={tf_input: batch_x,tf_output:batch_y})\n",
    "            \n",
    "            # Compute average loss\n",
    "            avg += loss / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \\\n",
    "                \"{:.9f}\".format(avg))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(tf_output, 1))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, \"float\"))\n",
    "    \n",
    "    total_test_data = len(newsgroups_test.target)\n",
    "    \n",
    "    batch_x_test,batch_y_test = get_batch(newsgroups_test,0,total_test_data)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy.eval({tf_input: batch_x_test, tf_output: batch_y_test}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "neuron_net_newsgroups.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
